# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
import grpc

from minFQ.rpc import statistics_pb2 as minknow_dot_rpc_dot_statistics__pb2


class StatisticsServiceStub(object):
  # missing associated documentation comment in .proto file
  pass

  def __init__(self, channel):
    """Constructor.

    Args:
      channel: A grpc.Channel.
    """
    self.stream_duty_time = channel.unary_stream(
        '/ont.rpc.statistics.StatisticsService/stream_duty_time',
        request_serializer=minknow_dot_rpc_dot_statistics__pb2.StreamDutyTimeRequest.SerializeToString,
        response_deserializer=minknow_dot_rpc_dot_statistics__pb2.StreamDutyTimeResponse.FromString,
        )
    self.get_duty_time = channel.unary_unary(
        '/ont.rpc.statistics.StatisticsService/get_duty_time',
        request_serializer=minknow_dot_rpc_dot_statistics__pb2.GetDutyTimeRequest.SerializeToString,
        response_deserializer=minknow_dot_rpc_dot_statistics__pb2.GetDutyTimeResponse.FromString,
        )
    self.stream_throughput = channel.unary_stream(
        '/ont.rpc.statistics.StatisticsService/stream_throughput',
        request_serializer=minknow_dot_rpc_dot_statistics__pb2.StreamCumulativeThroughputRequest.SerializeToString,
        response_deserializer=minknow_dot_rpc_dot_statistics__pb2.StreamCumulativeThroughputResponse.FromString,
        )
    self.get_throughput = channel.unary_unary(
        '/ont.rpc.statistics.StatisticsService/get_throughput',
        request_serializer=minknow_dot_rpc_dot_statistics__pb2.GetCumulativeThroughputRequest.SerializeToString,
        response_deserializer=minknow_dot_rpc_dot_statistics__pb2.GetCumulativeThroughputResponse.FromString,
        )


class StatisticsServiceServicer(object):
  # missing associated documentation comment in .proto file
  pass

  def stream_duty_time(self, request, context):
    """Tracks how much time has been spent in each channel state, aggregated across all the channels

    Will fail with FAILED_PRECONDITION if minknow is not acquiring data unless `wait_for_processing` is set to True,
    then it will block and wait for data to start acquiring.

    The first response will give you all the data it can

    Since 1.13
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def get_duty_time(self, request, context):
    """Gets a decimated history of the duty time for a particular acquisition period. Minimum time is 15 minutes per bucket

    Since 1.14
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def stream_throughput(self, request, context):
    """A histogram of estimated read lengths (based on events)

    The first response(s) will give you the latest data, then the responses after that will only 
    contain buckets that have changed. The initial state may be sent over multiple messages

    Currently unimplemented
    rpc stream_read_length (StreamReadLengthRequest) returns (stream StreamReadLengthResponse) {}

    A 2D histogram between basecall length and qscore

    The first response(s) will give you the latest data, then the responses after that will only 
    contain buckets that have changed. The initial state may be sent over multiple messages

    Currently unimplemented
    rpc stream_heatmap (StreamHeatmapRequest) returns (stream StreamHeatmapResponse) {}

    Tracks experiment throughput across all channels over time

    The first response will give you all the data it can.

    The stream will end once the current acquisition period ends, and a caller will need to
    reinvoke the rpc in order to get new throughput data.

    Since 1.14
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def get_throughput(self, request, context):
    """Gets a decimated history of the cumulative throughput for a particular acquisition period. Minimum time is 15 minutes per bucket

    Since 1.14
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')


def add_StatisticsServiceServicer_to_server(servicer, server):
  rpc_method_handlers = {
      'stream_duty_time': grpc.unary_stream_rpc_method_handler(
          servicer.stream_duty_time,
          request_deserializer=minknow_dot_rpc_dot_statistics__pb2.StreamDutyTimeRequest.FromString,
          response_serializer=minknow_dot_rpc_dot_statistics__pb2.StreamDutyTimeResponse.SerializeToString,
      ),
      'get_duty_time': grpc.unary_unary_rpc_method_handler(
          servicer.get_duty_time,
          request_deserializer=minknow_dot_rpc_dot_statistics__pb2.GetDutyTimeRequest.FromString,
          response_serializer=minknow_dot_rpc_dot_statistics__pb2.GetDutyTimeResponse.SerializeToString,
      ),
      'stream_throughput': grpc.unary_stream_rpc_method_handler(
          servicer.stream_throughput,
          request_deserializer=minknow_dot_rpc_dot_statistics__pb2.StreamCumulativeThroughputRequest.FromString,
          response_serializer=minknow_dot_rpc_dot_statistics__pb2.StreamCumulativeThroughputResponse.SerializeToString,
      ),
      'get_throughput': grpc.unary_unary_rpc_method_handler(
          servicer.get_throughput,
          request_deserializer=minknow_dot_rpc_dot_statistics__pb2.GetCumulativeThroughputRequest.FromString,
          response_serializer=minknow_dot_rpc_dot_statistics__pb2.GetCumulativeThroughputResponse.SerializeToString,
      ),
  }
  generic_handler = grpc.method_handlers_generic_handler(
      'ont.rpc.statistics.StatisticsService', rpc_method_handlers)
  server.add_generic_rpc_handlers((generic_handler,))
